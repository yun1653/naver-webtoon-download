1. 네이버는 대부분 jquery가 잘 먹지 않는다. 네이버 측에서 jquery가 잘 먹히지 않도록 해 둔것이다. 개발자 도구 콘솔에서 제이쿼리가 먹히게 하기 위해서는 jquery compressed mini 버전을 복사해서 콘솔에다 붙여넣고 엔터치면 이후부터는 잘 될것이다.

2. 네이버에서 웹툰 이미지 같은 것을 크롤링하려고 하면 403 forbidden 으로 잘 안되는 경우가 있다. 네이버의 레퍼러(referer) 정책 때문이다. 즉 어느곳에서 이미지를 요청하는지를 확인하여 네이버 사이트 내에서 요청이 왔으면 허용해주고 다른곳에서 요청하면 금지시키는 것이다.

 이것을 해결하려면 다음과 같이 해보자.
 - 크롤링 해당 페이지에서 "개발자도구 네트워크"를 열어둔 상태에서 크롬의 새로고침 아이콘 오른쪽 마우스 후 "강력 새로고침"
 - 네트워크에 나오는 이미지를 클릭해서 "요청 항목의 referer 를 확인해서 복사한다. 근데 이 레퍼러는 상단 주소창의 주소와 값이 같다.
 - request를 보낼때 Header에 referer를 넣어서 보낸다.
 - const options = {
    url: 'https://comic.naver.com/...&weekday=thu',
    headers: {
      'referer': 'https://comic.naver.com/...&weekday=thu',
      'encoding': null,
      }
    };
  
3. 그림 파일을 요청할 경우에는 encoding 이 바이너리 파일로 받아야 합니다. request 모듈의 경우 encoding의 기본값(default)는 utf8입니다. 때문에 바이너리파일인 이미지를 정상적으로 받기 위해서는 encoding = null로 해주라는 매뉴얼이 있읍니다. 그래서 위의 옵션 항목에 추가로 encoding = null을 넣어 줍니다.

4. fs.writeFile 도 encoding 기본값은 utf8 입니다. 그래서 이미지 파일을 쓰기 위해서는 encoding 값을 null로 바꿔줘야 합니다. 
   ex) fs.writeFile(경로와이름,data,encoding값,완료되면 실행될 콜백) : fs.writeFile(path,data,null,(err)=>{});

5. 딜레이 시간 없이 크롤링하면 timeout 에러가 발생할 것이다. 계속 시도하면 ip를 차단당할 수도 있다. 그래서 보통은 거의 딜레이를 시키는 코딩을 하는 것이다. 그리고 항상 웹 요청은 실패할 수 있다는 것을 염두에 두고 코딩하는 것이 좋다. 특히 스크래핑의 경우에는 매우 중요하다.

 해결방법
 - 첫번째는 요청들 사이에 딜레이를 집어 넣은 것이다. (setTimeout)
 - 두번째는 이렇게 딜레이를 넣었는데도 에러가 나오는 경우에 다시 자동으로 그 부분을 재요청하게 하는 것이다. (re_try)
 - 재요청은 무한정하면 절대 안되고 꼭 횟수(count)를 정해서 해야한다.(절대 허용될 수 없는 에러가 나는 경우 대비)

6. 네이버에서 로그인이 필요한 내용을 스크랩하려고 하면 실행해도 아무런 반응이 없는 것처럼 보인다. 해당 스크랩 원하는 url을 로그인 페이지로 리다이렉트 해버리기 때문에 스크랩 프로그램이 작동하지 않는다. 그렇다면 로그인을 스크랩 코딩안에 구현해야한다. 그렇게 하려면 네이버 로그인과 관련된 쿠키, 세션쿠키에 대해 알아야하고, 그 쿠키 값을 스크랩 프로그램에 넣어서 처리해야 한다.
npm의 request 매뉴얼을 자세히 보면 cookies와 관련된 내용이 나온다. 네이버 로그인과 관련된 쿠키는 NID_AUT 와 NID_SES 이다 이값을 주입하면 된다.



[참고영상]
https://www.youtube.com/watch?v=YUm3hwO6i8Q&list=PLqh5vK4CKWeZyaNrMmfGPJiPuGM0XX1kM&index=8
